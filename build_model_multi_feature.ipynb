{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richarddowney/Documents/netflix_movie_prediction/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDED_COL_NAMES = [\"age_certification\"]\n",
    "NUM_NUMERIC_COLS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Develop model with multiple features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data/netflix_movies_single_genre.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path: str, features: list):\n",
    "    \"\"\"Read the data, keep only the features needed and drop missing\"\"\"\n",
    "\n",
    "    # Read the data\n",
    "    df = pd.read_csv(data_path)\n",
    "\n",
    "    # Get only the description and genre\n",
    "    df = df.loc[:, features]\n",
    "\n",
    "    # Remove missing values from description\n",
    "    df = df.dropna(subset=[\"description\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(DATA_PATH, features = [\"description\", \n",
    "                                      \"runtime\", \n",
    "                                      \"imdb_score\", \n",
    "                                      \"age_certification\", \n",
    "                                      \"genre\"\n",
    "                                      ]\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df: pd.DataFrame, col: str, fill_value: str):\n",
    "\n",
    "    df[col] = df[col].fillna(fill_value)\n",
    "\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_missing(df, \"age_certification\", \"unknown\")\n",
    "df = fill_missing(df, \"imdb_score\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encode_columns(df: pd.DataFrame, cols: list):\n",
    "  \"\"\"\n",
    "  Function to label encode columns\n",
    "\n",
    "  Args:\n",
    "      df: The pandas DataFrame containing the column to encode.\n",
    "      cols: The columns to encode\n",
    "\n",
    "  Returns:\n",
    "      A new pandas DataFrame with the encoded columns.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create a label encoder\n",
    "  le = LabelEncoder()\n",
    "\n",
    "  # Encode the columns\n",
    "  enc_cols = df[cols].apply(le.fit_transform)\n",
    "\n",
    "  df_no_enc = df.drop(cols, axis = 1)\n",
    "\n",
    "  df_enc = pd.concat([df_no_enc, enc_cols], axis = 1)\n",
    "\n",
    "  return df_enc, le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enc, le = label_encode_columns(df=df, cols = EMBEDDED_COL_NAMES + [\"genre\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in EMBEDDED_COL_NAMES:\n",
    "    df_enc[col] = df_enc[col].astype('category')\n",
    "\n",
    "categorical_cols = df_enc.select_dtypes(include='category').columns.tolist()\n",
    "df_categorical = df_enc.loc[:, categorical_cols]\n",
    "embedded_cols = {n: len(col.cat.categories) for n,col in df_categorical.items() if len(col.cat.categories) > 2}\n",
    "embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame, target: str, test_size: float =0.2, random_state=None):\n",
    "  \"\"\"\n",
    "  Splits the DataFrame into train and test sets\n",
    "\n",
    "  Args:\n",
    "      df: DataFrame containing the features and target\n",
    "      target: String with the name of the target column\n",
    "      test_size: Float between 0.0 and 1.0 representing the proportion of data \n",
    "                 allocated to the test set (default is 0.2).\n",
    "      random_state: Integer seed for random number generation (for reproducibility).\n",
    "\n",
    "  Returns:\n",
    "      A tuple of four Pandas DataFrames containing the X and y for the train and test sets\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  X = df.drop(target, axis = 1)\n",
    "  y = df[target]\n",
    "\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "  X_train = X_train.reset_index(drop=True)\n",
    "  X_test = X_test.reset_index(drop=True)\n",
    "  y_train = y_train.reset_index(drop=True)\n",
    "  y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "  return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(df_enc, \"genre\", test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "bert_model = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataLoader(Dataset):\n",
    "    def __init__(self, X, y, embedded_col_names):\n",
    "        X = X.copy()\n",
    "        self.desc = X.loc[:, \"description\"]\n",
    "        self.X2 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n",
    "        self.X3 = X.drop(columns=embedded_col_names + [\"description\"]).copy().values.astype(np.float32) #numerical columns\n",
    "        self.y = y\n",
    "\n",
    "        #### Embedding encoder ####\n",
    "\n",
    "        # Preprocess the text\n",
    "        encoded_input = tokenizer(self.desc.tolist(), return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        # Get input IDs and attention mask\n",
    "        self.X1= encoded_input[\"input_ids\"]\n",
    "        self.attention_mask = encoded_input[\"attention_mask\"]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.attention_mask[idx], self.X2[idx], self.X3[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    return torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TokenDataLoader(X_train, y_train, EMBEDDED_COL_NAMES)\n",
    "test_ds = TokenDataLoader(X_test, y_test, EMBEDDED_COL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(test_ds, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGenreClassifier(nn.Module):\n",
    "    def __init__(self, embed_model, num_labels, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = embed_model\n",
    "        self.bert_lin = nn.Linear(768, 128)\n",
    "        \n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings)\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.bn3 = nn.BatchNorm1d(70)\n",
    "        self.dropout = nn.Dropout(0.2) \n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont+128, 200)\n",
    "        self.lin2 = nn.Linear(200, 70)\n",
    "        self.classifier = nn.Linear(70, num_labels)\n",
    "\n",
    "\n",
    "    def forward(self, X, mask, X_cat, X_cont):\n",
    "\n",
    "        # Categorical embeddings\n",
    "        x_cat_embed = [e(X_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x_cat_embed = torch.cat(x_cat_embed, 1)\n",
    "        x_cat_embed = self.dropout(x_cat_embed)\n",
    "\n",
    "        X_num = self.bn1(X_cont)\n",
    "\n",
    "        bert_embed = self.model(input_ids=X, attention_mask=mask)\n",
    "        bert_embed = self.dropout(bert_embed[0])\n",
    "        bert_embed = bert_embed[:,0,:].view(-1,768)\n",
    "        bert_embed = self.bert_lin(bert_embed)\n",
    "\n",
    "        x = torch.cat([x_cat_embed, bert_embed, X_num], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.classifier(x)\n",
    "                \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = df_enc[\"genre\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGenreClassifier(embed_model=bert_model, num_labels=NUM_LABELS, embedding_sizes=embedding_sizes, n_cont=NUM_NUMERIC_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"./simple_genre_classifier_v2.pt\"\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, train_dl):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for X, mask, X_cat, X_cont, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        logits = model(X, mask, X_cat, X_cont)\n",
    "        loss = criterion(logits.view(-1, NUM_LABELS), y.view(-1))\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loss(model, valid_dl):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for X, mask, X_cat, X_cont, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        logits = model(X, mask, X_cat, X_cont)\n",
    "        loss = criterion(logits.view(-1, NUM_LABELS), y.view(-1))\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(logits, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.99)\n",
    "\n",
    "def train_loop(model, epochs):\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optimizer, train_dl)\n",
    "        print(\"training loss: \", loss)\n",
    "        val_loss(model, valid_dl)\n",
    "        scheduler.step()\n",
    "        torch.save(model.state_dict(), \"simple_genre_classifier_v2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  2.9797281286708213\n",
      "valid loss 2.765 and accuracy 0.182\n",
      "training loss:  2.6888233798597923\n",
      "valid loss 2.503 and accuracy 0.324\n",
      "training loss:  2.475044599453883\n",
      "valid loss 2.368 and accuracy 0.358\n",
      "training loss:  2.309942432753355\n",
      "valid loss 2.271 and accuracy 0.399\n",
      "training loss:  2.173746128808256\n",
      "valid loss 2.154 and accuracy 0.441\n",
      "training loss:  2.052492932877326\n",
      "valid loss 2.092 and accuracy 0.453\n",
      "training loss:  1.9315529030499574\n",
      "valid loss 2.059 and accuracy 0.469\n",
      "training loss:  1.8056657689665427\n",
      "valid loss 1.999 and accuracy 0.477\n",
      "training loss:  1.6858866223001976\n",
      "valid loss 1.982 and accuracy 0.481\n",
      "training loss:  1.565968732107882\n",
      "valid loss 1.963 and accuracy 0.496\n",
      "training loss:  1.475085916816157\n",
      "valid loss 1.965 and accuracy 0.489\n",
      "training loss:  1.3714839946027446\n",
      "valid loss 2.034 and accuracy 0.491\n",
      "training loss:  1.276153812152704\n",
      "valid loss 1.929 and accuracy 0.508\n",
      "training loss:  1.1935841088476478\n",
      "valid loss 1.942 and accuracy 0.521\n",
      "training loss:  1.1189823373378767\n",
      "valid loss 1.936 and accuracy 0.513\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  1.066253229821017\n",
      "valid loss 1.971 and accuracy 0.507\n",
      "training loss:  0.9890745927718272\n",
      "valid loss 1.996 and accuracy 0.495\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "batch_size = 32\n",
    "valid_dl = DataLoader(test_ds, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "for X, mask, X_cat, X_cont, y in valid_dl:\n",
    "\n",
    "    model.eval()\n",
    "    logits = model(X, mask, X_cat, X_cont)\n",
    "    pred = torch.max(logits, 1)[1]\n",
    "    pred = list(pred.squeeze().detach().numpy())\n",
    "    true = list(y.squeeze().detach().numpy())\n",
    "\n",
    "    y_pred.extend(pred)\n",
    "    y_true.extend(true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_accuracy(y_pred, y_true, le):\n",
    "    \"\"\"\n",
    "    Obtains the class level accuracy with counts of correct and incorrectly classified\n",
    "\n",
    "    Args:\n",
    "        y_pred: Numpy array of predicted classes\n",
    "        y_true: Numpy array of true classes\n",
    "        le: Trained label encoder to convert labels back to descriptions of genre\n",
    "\n",
    "    Returns:\n",
    "        Pandas DataFrame with predictions\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    preds = pd.DataFrame([y_pred, y_true]).T\n",
    "    preds.columns = [\"y_pred\", \"y_true\"]\n",
    "    preds[\"correct\"] = np.where(preds[\"y_pred\"]==preds[\"y_true\"], 1, 0)\n",
    "    preds[\"genre\"] = le.inverse_transform(list(preds[\"y_true\"]))\n",
    "\n",
    "    genre_predictions = pd.DataFrame(preds.groupby(\"genre\")['correct'].agg(['mean', 'sum', 'count']))\n",
    "    genre_predictions[\"incorrect\"] = genre_predictions[\"count\"] - genre_predictions[\"sum\"]\n",
    "    genre_predictions = genre_predictions.sort_values(by=\"incorrect\", ascending=False)\n",
    "    genre_predictions.columns=[\"accuracy\", \"correct\", \"number_movies\", \"incorrect\"]\n",
    "\n",
    "    return genre_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>correct</th>\n",
       "      <th>number_movies</th>\n",
       "      <th>incorrect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>0.437751</td>\n",
       "      <td>109</td>\n",
       "      <td>249</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>135</td>\n",
       "      <td>216</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>0.271429</td>\n",
       "      <td>19</td>\n",
       "      <td>70</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>family</th>\n",
       "      <td>0.152542</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romance</th>\n",
       "      <td>0.566038</td>\n",
       "      <td>60</td>\n",
       "      <td>106</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thriller</th>\n",
       "      <td>0.351852</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime</th>\n",
       "      <td>0.697674</td>\n",
       "      <td>60</td>\n",
       "      <td>86</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>documentation</th>\n",
       "      <td>0.535714</td>\n",
       "      <td>30</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scifi</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fantasy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animation</th>\n",
       "      <td>0.484848</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reality</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>european</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>horror</th>\n",
       "      <td>0.772727</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sport</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>western</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               accuracy  correct  number_movies  incorrect\n",
       "genre                                                     \n",
       "drama          0.437751      109            249        140\n",
       "comedy         0.625000      135            216         81\n",
       "action         0.271429       19             70         51\n",
       "family         0.152542        9             59         50\n",
       "romance        0.566038       60            106         46\n",
       "thriller       0.351852       19             54         35\n",
       "crime          0.697674       60             86         26\n",
       "documentation  0.535714       30             56         26\n",
       "scifi          0.459459       17             37         20\n",
       "fantasy        0.000000        0             17         17\n",
       "animation      0.484848       16             33         17\n",
       "reality        0.466667       14             30         16\n",
       "history        0.066667        1             15         14\n",
       "european       0.000000        0             12         12\n",
       "horror         0.772727       34             44         10\n",
       "music          0.757576       25             33          8\n",
       "sport          0.650000       13             20          7\n",
       "war            0.631579       12             19          7\n",
       "western        0.000000        0              1          1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_accuracy(y_pred, y_true, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
